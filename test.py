from sentence_transformers import SentenceTransformer, util
from pymongo import MongoClient
import torch
import logging
import sys
import os
import re
import random
import tkinter as tk
from tkinter import scrolledtext, Button, Entry, Label, PhotoImage, font, messagebox
import spacy
import nltk
from nltk.corpus import wordnet

# Download required NLTK data
try:
    wordnet.synsets('test')  # Test if wordnet is available
except LookupError:
    nltk.download('wordnet')

# Load spaCy model
try:
    nlp = spacy.load("en_core_web_sm")
    logging.info("‚úÖ spaCy model loaded successfully.")
except OSError:
    logging.error("‚ùå Could not load spaCy model. Downloading 'en_core_web_sm'...")
    try:
        import spacy.cli
        spacy.cli.download("en_core_web_sm")
        nlp = spacy.load("en_core_web_sm")
        logging.info("‚úÖ spaCy model downloaded and loaded successfully.")
    except Exception as e:
        logging.error(f"‚ùå Error downloading or loading spaCy model: {e}")
        nlp = None
except Exception as e:
    logging.error(f"‚ùå Error loading spaCy model: {e}")
    nlp = None

# Logging setup
logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S',
                        level=logging.INFO,
                        handlers=[logging.StreamHandler(stream=sys.stdout)])

def clean_text(text):
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s.,;\'"():%/-]', '', text)
    return text.strip()

def assess_compliance_risk(law1_text, law2_text, query=""):
    risk_score = 0.0
    explanation = "No significant conflict detected."

    if "shall not" in law1_text and "shall" in law2_text:
        risk_score = 0.6 + random.uniform(0, 0.2)
        explanation = f"‚ö† Conflict regarding '{query}': One law prohibits what another mandates. Recommendation: Adhere to the stricter clause."
    elif "must" in law1_text and "may not" in law2_text:
        risk_score = 0.6 + random.uniform(0, 0.2)
        explanation = f"‚ö† Conflict regarding '{query}': One law requires what another forbids. Recommendation: Clarify the intent with regulatory counsel."
    elif "is prohibited" in law1_text and "is allowed" in law2_text:
        risk_score = 0.7 + random.uniform(0, 0.2)
        explanation = f"üö® Direct contradiction on '{query}': One law allows what another prohibits. Recommendation: Follow the most recent or stricter law."
    elif "should" in law1_text and "is not required" in law2_text:
        risk_score = 0.35
        explanation = f"‚ö† Potential ambiguity in guidance for '{query}'. Recommendation: Treat 'should' as 'must' for better compliance posture."

    return risk_score, explanation

def expand_query(query, top_n=5):
    """
    Expands the query using synonyms and related terms from spaCy and WordNet.

    Args:
        query (str): The original query.
        top_n (int, optional): The number of expanded queries to return. Defaults to 5.

    Returns:
        list: A list of expanded queries.
    """
    if nlp is None:
        logging.warning("spaCy model not loaded. Query expansion will not be performed.")
        return [query]

    doc = nlp(query)
    expanded_queries = set()
    expanded_queries.add(query)  # Add the original query

    for token in doc:
        if token.pos_ in ["NOUN", "ADJ", "VERB"]:  # Expand only nouns, adjectives, and verbs
            # Add synonyms based on wordnet
            try:
                synsets = wordnet.synsets(token.text)
                for synset in synsets:
                    for lemma in synset.lemmas():
                        expanded_queries.add(lemma.name().replace("_", " "))
            except LookupError as e:
                logging.warning(f"WordNet LookupError: {e}. Please ensure nltk data is downloaded. Try: nltk.download('wordnet')")
            except Exception as e:
                logging.warning(f"Error expanding query with WordNet: {e}")

    # Convert set to list and limit the number of expanded queries
    expanded_queries_list = list(expanded_queries)
    if len(expanded_queries_list) > top_n:
        return random.sample(expanded_queries_list, top_n)
    else:
        return expanded_queries_list

def main():
    try:
        model_path = "trained_sbert_mininglaw_risk_aware_with_negatives"
        if not os.path.exists(model_path):
            raise ValueError(f"Trained model not found at {model_path}")
        model = SentenceTransformer(model_path)
        logging.info(f"‚úÖ Loaded trained model from '{model_path}'")
    except Exception as e:
        logging.error(f"‚ùå Error loading model: {e}")
        return

    client = MongoClient("mongodb://localhost:27017/")
    db = client["mining_law_db"]
    pdf_data_collection = db["pdf_data"]

    try:
        pdf_data = list(pdf_data_collection.find({"text": {"$exists": True}}))
        if not pdf_data:
            logging.warning("‚ö† No data found in 'pdf_data'")
            client.close()
            return
        logging.info(f"üìÑ Loaded {len(pdf_data)} documents from MongoDB")
    except Exception as e:
        logging.error(f"‚ùå Failed to load data: {e}")
        client.close()
        return

    try:
        all_texts = [doc["text"] for doc in pdf_data]
        pdf_embeddings = model.encode(all_texts, convert_to_tensor=True, show_progress_bar=True)
        logging.info("‚úÖ Embedded all law documents")
    except Exception as e:
        logging.error(f"‚ùå Error embedding documents: {e}")
        client.close()
        return

    def search_laws(query):
        try:
            # Expand the query
            expanded_queries = expand_query(query)
            logging.info(f"Expanded queries: {expanded_queries}")

            # Encode all expanded queries
            query_embeddings = model.encode(expanded_queries, convert_to_tensor=True)

            # Calculate similarities for each expanded query and average them
            all_similarities = []
            for query_embedding in query_embeddings:
                similarities = util.pytorch_cos_sim(query_embedding, pdf_embeddings)[0]
                all_similarities.append(similarities)

            # Average the similarities across all expanded queries
            averaged_similarities = torch.mean(torch.stack(all_similarities), dim=0)

            # Get top results based on averaged similarities
            top_results = torch.topk(averaged_similarities, 3)

            results_text.delete(1.0, tk.END)

            top_indices = top_results.indices.tolist()
            top_scores = top_results.values.tolist()

            for i, idx in enumerate(top_indices):
                doc = pdf_data[idx]
                filename = doc.get("filename", "Unknown")
                excerpt = doc.get("text", "")[:300].strip()
                score = top_scores[i]
                
                if score < 0.16:  # Check for similarity score below 0.2
                    results_text.insert(tk.END, "\n‚ùå Irrelevant question. The query does not match any relevant legal text.\n")
                    return  # Exit the function if the score is too low

                results_text.insert(tk.END, f"\nüîπ Match {i+1} for query: '{query}'\n")
                results_text.insert(tk.END, f"üìÑ Document: {filename}\n")
                results_text.insert(tk.END, f"üìù Content Excerpt: {excerpt}...\n")
                results_text.insert(tk.END, f"üîó Similarity Score: {score:.4f}\n")
                results_text.insert(tk.END, "-" * 60 + "\n")

            results_text.insert(tk.END, "\n‚öñÔ∏è Compliance Risk Evaluation\n")
            contradiction_flag = False

            for i in range(len(top_indices)):
                for j in range(i + 1, len(top_indices)):
                    law1 = pdf_data[top_indices[i]].get("text", "")
                    law2 = pdf_data[top_indices[j]].get("text", "")
                    risk_score, explanation = assess_compliance_risk(law1, law2, query)

                    if risk_score > 0.0:
                        contradiction_flag = True
                        results_text.insert(tk.END, f"\nüö® Contradiction Detected Between Match {i+1} and Match {j+1}\n")
                        results_text.insert(tk.END, f"üî∫ Risk Score: {risk_score:.2f}\n")
                        results_text.insert(tk.END, f"üìå Legal Recommendation: {explanation}\n")

                        # ‚ûï Suggest an alternative non-conflicting document
                        excluded = {top_indices[i], top_indices[j]}
                        for k, doc in enumerate(pdf_data):
                            if k in excluded:
                                continue
                            alt_text = doc.get("text", "")
                            alt_score = float(util.pytorch_cos_sim(query_embedding, model.encode(alt_text, convert_to_tensor=True))[0])
                            if alt_score > 0.5:
                                results_text.insert(tk.END, f"\nüß≠ Suggested Alternative Law: {doc.get('filename', 'Unnamed')}\n")
                                results_text.insert(tk.END, f"üìë Excerpt: {alt_text[:200]}...\n")
                                results_text.insert(tk.END, f"üîó Similarity: {alt_score:.4f}\n")
                                break

                    results_text.insert(tk.END, "-" * 60 + "\n")

            if not contradiction_flag:
                results_text.insert(tk.END, "\n‚úÖ No contradictions detected. The legal provisions appear consistent.\n")
                results_text.insert(tk.END, "-" * 60 + "\n")

        except Exception as e:
            logging.error(f"‚ùå Query error: {e}")
            results_text.insert(tk.END, f"\n‚ùå Error processing query: {e}")

    def on_search_button_click():
        query = query_entry.get().strip()
        if query:
            search_laws(query)

    root = tk.Tk()
    root.title("Mining Law Chatbot")

    # --- Styling ---
    bg_color = '#E6F2FF'  # Light blue
    text_color = '#2E3B55'  # Dark blue-gray
    button_color = '#66B2FF'  # Medium blue
    highlight_color = '#A0D6FF' # Lighter blue for highlights
    font_family = "Arial"  # Change this to your desired font family
    font_size = 11
    font_style = font.Font(family=font_family, size=font_size)
    bold_font = font.Font(family=font_family, size=font_size, weight="bold")

    root.configure(bg=bg_color)

    # --- Header ---
    header_font = font.Font(family=font_family, size=18, weight="bold")
    header_label = Label(root, text="Mining Law Compliance Chatbot", bg=bg_color, fg=text_color, font=header_font)
    header_label.pack(pady=(10, 20))

    # --- Query Input ---
    query_label = Label(root, text="üîç Enter your mining law question:", bg=bg_color, fg=text_color, font=bold_font)
    query_label.pack(pady=(0, 5))

    query_entry = Entry(root, width=60, font=font_style, bg='white', fg=text_color)
    query_entry.pack(pady=(0, 10))

    search_button = Button(root, text="Search", command=on_search_button_click, bg=button_color, fg='white', font=bold_font, relief=tk.RAISED, borderwidth=2)
    search_button.pack(pady=(0, 15))
    search_button.config(highlightbackground=bg_color)  # Remove the border

    # --- Results Output ---
    results_label = Label(root, text="üìã Results, Contradictions & Recommendations:", bg=bg_color, fg=text_color, font=bold_font)
    results_label.pack()

    results_text = scrolledtext.ScrolledText(root, width=90, height=30, bg='#F9F9F9', fg=text_color, font=font_style)
    results_text.pack(pady=(0, 20))

    # --- Center Window ---
    root.eval('tk::PlaceWindow . center')

    # --- Run Main Loop ---
    root.mainloop()
    client.close()

if __name__ == "__main__":
    main()
